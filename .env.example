# LLMプロバイダー設定
# 利用可能なプロバイダー: openai, gemini, anthropic, azure
LLM_PROVIDER=gemini

# ===== デフォルト設定（全処理共通） =====
# LLM Model Configuration
LLM_MODEL=gemini-1.5-flash

# LLM Generation Parameters
# Temperature controls randomness in output (0.0 to 2.0)
# Higher values = more random, Lower values = more deterministic
LLM_TEMPERATURE=1.0

# Top-p controls diversity via nucleus sampling (0.0 to 1.0)
# Higher values = more diverse, Lower values = more focused
LLM_TOP_P=0.95

# ===== OpenAI設定 =====
OPENAI_API_KEY=your_openai_api_key_here

# ===== Gemini設定 =====
GEMINI_API_KEY=your_gemini_api_key_here
# 互換性のため（旧設定名もサポート）
GOOGLE_API_KEY=your_gemini_api_key_here

# ===== Anthropic設定 =====
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ===== Azure OpenAI設定 =====
AZURE_API_KEY=your_azure_api_key_here
AZURE_API_BASE=https://your-resource.openai.azure.com/

# ===== プロット生成専用設定（オプション） =====
# プロット生成では構造的で一貫性のある出力が望ましいため、
# デフォルトより低めのTemperatureを推奨
PLOT_MODEL=gemini-1.5-flash
PLOT_TEMPERATURE=0.8
PLOT_TOP_P=0.9

# ===== エピソード生成専用設定（オプション） =====
# エピソード生成では創造的で表現豊かな出力が望ましいため、
# デフォルトと同等かやや高めのTemperatureを推奨
EPISODE_MODEL=gemini-1.5-flash
EPISODE_TEMPERATURE=1.0
EPISODE_TOP_P=0.95

# ===== 設定の優先順位 =====
# 1. 専用設定（PLOT_* または EPISODE_*）
# 2. デフォルト設定（LLM_*）
# 3. 内蔵デフォルト値
#
# 例：プロット生成時
# PLOT_TEMPERATURE → LLM_TEMPERATURE → 1.0 の順で決定

# ===== 推奨設定値とモデル =====
# プロット生成: TEMPERATURE=0.7-0.9 (構造的)
# エピソード生成: TEMPERATURE=1.0-1.2 (創造的)
# 
# 利用可能なモデル:
# OpenAI: gpt-4o, gpt-4o-mini, gpt-3.5-turbo
# Gemini: gemini-1.5-flash, gemini-1.5-pro, gemini-2.5-flash
# Anthropic: claude-3-haiku-20240307, claude-3-sonnet-20240229, claude-3-opus-20240229
# Azure: お使いのデプロイメント名を指定

# ===== プロバイダー切り替え例 =====
# OpenAIを使用する場合:
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o-mini
# OPENAI_API_KEY=your_actual_api_key

# Anthropicを使用する場合:
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-haiku-20240307
# ANTHROPIC_API_KEY=your_actual_api_key
